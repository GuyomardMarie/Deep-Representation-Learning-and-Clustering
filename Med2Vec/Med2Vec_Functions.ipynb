{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides functions to compute Med2Vec patient representations.\n",
    "\n",
    "#### References\n",
    "\n",
    "Multi-layer Representation Learning for Medical Concepts, E. Choi (2016)\n",
    "\n",
    "RETAIN: Interpretable Predictive Model in Healthcare using Reverse Time Attention Mechanism, E. Choi (2016)\n",
    "\n",
    "Doctor AI: Predicting Clinical Events via Recurrent Neural Networks; E. Choi (2016)\n",
    "\n",
    "#### Github with the authors codes\n",
    "\n",
    "https://github.com/mp2893/med2vec\n",
    "\n",
    "\n",
    "#### Python environmment\n",
    "- Python 2.7\n",
    "- Required Packages: Theano, Pickle, Scikit-learn and Scipy\n",
    "\n",
    "#### Complementary Functions\n",
    "\n",
    "1. En evaluation function: Evaluate_Med2Vec\n",
    "        This function ables to compute the loss of a trained model on a new sample (different than the one used to fit the model)\n",
    "\n",
    "2. A Training Function: Train_Med2Vec\n",
    "        This function ables to train and evaluate the model on a validation sample to prevent overfitting:\n",
    "        - Split the sample into a train set (80%) and a validation one (20%)\n",
    "        - Train the Med2Vec architecture on the training sample\n",
    "        - Evaluate the model on both training and validation samples by computing the losses\n",
    "        - Returns the losses on the training and test sets\n",
    "\n",
    "3. Gridsearch of hyperparameters\n",
    "        This function aims at optimizing the following hyperparameters composing Med2Vec model:\n",
    "        - embDimSize: dimension of the intermediate latent space\n",
    "        - hiddenDimSize: dimension of the latent space \n",
    "        - window_size: size of the context window \n",
    "\n",
    "        All set of hyperparameters to be tested given as input are used to train the model on a training set (80% of the sample). \n",
    "\n",
    "        The optimal set of hyperparameters is the one minimizing the loss function on a validation sample (20% of the sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package of the authors\n",
    "\n",
    "https://github.com/mp2893/med2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from med2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Med2Vec(File) : \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    File : dict\n",
    "        Dictionnary with the following keys :\n",
    "        - 'seqFile' (str) : The path to the Pickled file containing visit information of patients\n",
    "        - 'labelFile' (str) : The path to the Pickled file containing grouped visit information of patients\n",
    "        - 'outFile' (str) : The path to the output models\n",
    "        - 'demoFile' (str) : The path to the Pickled file containing demographic information of patients\n",
    "        - 'numXcodes' (int) : The number of unique input medical codes\n",
    "        - 'numYcodes' (int) : The number of unique output medical codes (the number of unique grouped codes)\n",
    "        - 'demoSize' (int) : The size of the demographic information vector\n",
    "        - 'embDimSize' (int) : The size of the code representation\n",
    "        - 'hiddenDimSize' (int) : The size of the visit representation\n",
    "        - 'windowSize' (int) : The size of the visit context window (range: 1,2,3,4,5)\n",
    "        - 'batchSize' (int) : The size of the demographic information vector\n",
    "        - 'maxEpochs' (int) : The number of training epochs\n",
    "        - 'logEps' (float) : The learning rate\n",
    "        - 'L2_reg' (float) : L2 regularization for the code representation matrix W_c\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss_train : float\n",
    "        The value of the loss on the training sample.  \n",
    "    loss_test : float\n",
    "        The value of the loss on the test sample.\n",
    "    '''\n",
    "\n",
    "    # Split Train / Test\n",
    "    if File['numYcodes'] > 0 :\n",
    "        seqFile_train, seqFile_test, labelFile_train, labelFile_test = train_test_split(np.array(pickle.load(open(File['seqFile'], 'rb'))), np.array(pickle.load(open(File['labelFile'], 'rb'))), test_size=0.2, random_state=42)\n",
    "        pickle.dump(seqFile_train, open(File['outFile']+'/seqFile_train', 'wb'), -1)\n",
    "        pickle.dump(labelFile_train, open(File['outFile']+'/labelFile_train', 'wb'), -1)\n",
    "        pickle.dump(seqFile_test, open(File['outFile']+'/seqFile_test', 'wb'), -1)\n",
    "        pickle.dump(labelFile_test, open(File['outFile']+'/labelFile_test', 'wb'), -1)\n",
    "    else :\n",
    "        seqFile_train, seqFile_test = train_test_split(np.array(pickle.load(open(File['seqFile'], 'rb'))),  test_size=0.2, random_state=42)\n",
    "        pickle.dump(seqFile_train, open(File['outFile']+'/seqFile_train', 'wb'), -1)\n",
    "        pickle.dump(seqFile_test, open(File['outFile']+'/seqFile_test', 'wb'), -1)\n",
    "\n",
    "    # Train the model\n",
    "    if File['numYcodes'] > 0 :\n",
    "        train_med2vec(seqFile = File['outFile']+'/seqFile_train',\n",
    "                    labelFile = File['outFile']+'/labelFile_train',\n",
    "                    demoFile = File['demoFile'],\n",
    "                    outFile = File['outFile'], \n",
    "                    numXcodes = File['numXcodes'],\n",
    "                    numYcodes = File['numYcodes'],\n",
    "                    demoSize = File['demoSize'],\n",
    "                    embDimSize = File['embDimSize'], \n",
    "                    hiddenDimSize = File['hiddenDimSize'],\n",
    "                    windowSize = File['windowSize'],\n",
    "                    batchSize = File['batchSize'],\n",
    "                    maxEpochs = File['maxEpochs'],\n",
    "                    logEps = File['logEps'],\n",
    "                    L2_reg = File['L2_reg'])\n",
    "    else :\n",
    "        train_med2vec(seqFile = File['outFile']+'/seqFile_train',\n",
    "                    labelFile = File['labelFile'],\n",
    "                    demoFile = File['demoFile'],\n",
    "                    outFile = File['outFile'], \n",
    "                    numXcodes = File['numXcodes'],\n",
    "                    numYcodes = File['numYcodes'],\n",
    "                    demoSize = File['demoSize'],\n",
    "                    embDimSize = File['embDimSize'], \n",
    "                    hiddenDimSize = File['hiddenDimSize'],\n",
    "                    windowSize = File['windowSize'],\n",
    "                    batchSize = File['batchSize'],\n",
    "                    maxEpochs = File['maxEpochs'],\n",
    "                    logEps = File['logEps'],\n",
    "                    L2_reg = File['L2_reg'])\n",
    "    \n",
    "    # Evaluate\n",
    "    Filetrain = File.copy()\n",
    "    Filetest = File.copy()\n",
    "    Filetrain['seqFile'] = File['outFile']+'/seqFile_train'\n",
    "    Filetest['seqFile'] = File['outFile']+'/seqFile_test'\n",
    "    if File['numYcodes'] > 0 :\n",
    "        Filetrain['labelFile'] = File['outFile']+'/labelFile'\n",
    "        Filetest['labelFile'] = File['outFile']+'/labelFile_test'\n",
    "        \n",
    "    loss_train = Evaluate_Med2Vec(Filetrain, File['outFile']+ '.' +str(File['maxEpochs']-1) + '.npz', Filetrain) \n",
    "    loss_test = Evaluate_Med2Vec(Filetest, File['outFile']+ '.' +str(File['maxEpochs']-1) + '.npz', Filetest) \n",
    "\n",
    "    return loss_train, loss_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Med2Vec(File, model, options) : \n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        File : dict\n",
    "                Dictionnary with the following keys :\n",
    "                - 'seqFile' (str) : The path to the Pickled file containing visit information of patients\n",
    "                - 'labelFile' (str) : The path to the Pickled file containing grouped visit information of patients\n",
    "                - 'outFile' (str) : The path to the output models\n",
    "                - 'demoFile' (str) : The path to the Pickled file containing demographic information of patients\n",
    "                - 'numXcodes' (int) : The number of unique input medical codes\n",
    "                - 'numYcodes' (int) : The number of unique output medical codes (the number of unique grouped codes)\n",
    "                - 'demoSize' (int) : The size of the demographic information vector\n",
    "                - 'batchSize' (int) : The size of the demographic information vector\n",
    "                - 'maxEpochs' (int) : The number of training epochs\n",
    "                - 'logEps' (float) : The learning rate\n",
    "                - 'L2_reg' (float) : L2 regularization for the code representation matrix W_c\n",
    "        Model : str\n",
    "                Path to the saved trained model.\n",
    "        options : dict\n",
    "                Dictionnary of the hyper parameters containing the following keys :\n",
    "                - 'embDimSize' (int) : The size of the code representation\n",
    "                - 'hiddenDimSize' (int) : The size of the visit representation\n",
    "                - 'windowSize' (int) : The size of the visit context window (range: 1,2,3,4,5)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss_value : float\n",
    "                The value of the loss on the sample.        \n",
    "        '''\n",
    "\n",
    "        # Model\n",
    "        model_param = np.load(model)\n",
    "        tparams = {'W_emb': model_param['W_emb'],\n",
    "                'b_emb': model_param['b_emb'],\n",
    "                'W_hidden': model_param['W_hidden'],\n",
    "                'b_hidden': model_param['b_hidden'],\n",
    "                'W_output': model_param['W_output'],\n",
    "                'b_output': model_param['b_output']}\n",
    "\n",
    "        # Data\n",
    "        seqs, demos, labels = load_data(File['seqFile'], File['demoFile'], File['labelFile'])\n",
    "        \n",
    "        if File['numYcodes'] > 0 :\n",
    "                x_data, y_data, mask_data, iVector_data, jVector_data = padMatrix(seqs, labels, File)\n",
    "        else :\n",
    "                x_data, mask_data, iVector_data, jVector_data = padMatrix(seqs, labels, File)\n",
    "\n",
    "        new_options = {'numXcodes': File['numXcodes'],\n",
    "                'numYcodes': File['numYcodes'],\n",
    "                'demoSize': File['demoSize'],\n",
    "                'embDimSize': options['embDimSize'],\n",
    "                'hiddenDimSize': options['hiddenDimSize'],\n",
    "                'windowSize': options['windowSize'],\n",
    "                'logEps': File['logEps'],\n",
    "                'L2_reg': File['L2_reg']}\n",
    "        \n",
    "        # Compute loss\n",
    "        if File['demoSize'] > 0 :\n",
    "                if File['numYcodes'] > 0:\n",
    "                        x, d, y, mask, iVector, jVector, total_cost = build_model(tparams, new_options)\n",
    "                        eval_cost = theano.function(inputs=[x, d, y, mask, iVector, jVector],  outputs=total_cost)\n",
    "                        loss_value = eval_cost(x_data, demos, y_data, mask_data, iVector_data, jVector_data)\n",
    "                else :\n",
    "                        x, d, mask, iVector, jVector, total_cost = build_model(tparams, new_options)\n",
    "                        eval_cost = theano.function(inputs=[x, d, mask, iVector, jVector],  outputs=total_cost)\n",
    "                        loss_value = eval_cost(x_data, demos, mask_data, iVector_data, jVector_data)\n",
    "        else :\n",
    "                if File['numYcodes'] > 0:\n",
    "                        x, y, mask, iVector, jVector, total_cost = build_model(tparams, new_options)\n",
    "                        eval_cost = theano.function(inputs=[x, y, mask, iVector, jVector],  outputs=total_cost)\n",
    "                        loss_value = eval_cost(x_data, y_data, mask_data, iVector_data, jVector_data)\n",
    "                else :\n",
    "                        x, mask, iVector, jVector, total_cost = build_model(tparams, new_options)\n",
    "                        eval_cost = theano.function(inputs=[x, mask, iVector, jVector],  outputs=total_cost)\n",
    "                        loss_value = eval_cost(x_data, mask_data, iVector_data, jVector_data)\n",
    "        \n",
    "        return loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch of the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gridsearch_Med2Vec(File, embDimSize_list, hiddenDimSize_list, window_size_list) : \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    File : dict\n",
    "        Dictionnary with the following keys :\n",
    "        - 'seqFile' (str) : The path to the Pickled file containing visit information of patients\n",
    "        - 'labelFile' (str) : The path to the Pickled file containing grouped visit information of patients\n",
    "        - 'outFile' (str) : The path to the output models\n",
    "        - 'demoFile' (str) : The path to the Pickled file containing demographic information of patients\n",
    "        - 'numXcodes' (int) : The number of unique input medical codes\n",
    "        - 'numYcodes' (int) : The number of unique output medical codes (the number of unique grouped codes)\n",
    "        - 'demoSize' (int) : The size of the demographic information vector\n",
    "        - 'batchSize' (int) : The size of the demographic information vector\n",
    "        - 'maxEpochs' (int) : The number of training epochs\n",
    "        - 'logEps' (float) : The learning rate\n",
    "        - 'L2_reg' (float) : L2 regularization for the code representation matrix W_c\n",
    "    embDimSize_list : list\n",
    "        List of the embedding size (for the code representation) to be tested.\n",
    "    hiddenDimSize_list : list\n",
    "        List of the hidden size (for the visit representation) to be tested.\n",
    "    window_size_list : list\n",
    "        List of the window sizes to be tested.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_hyperparmeters : DataFrame\n",
    "        For each pairs of hyperparameters tested, the loss associated on the validation set is stocked.\n",
    "    '''\n",
    "\n",
    "    df_hyperparameters = pd.DataFrame(columns=['embDimSize', 'hiddenDimSize', 'windowSize', 'Loss_test'])\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    # Train / Test Split\n",
    "    if len(File['labelFile']) > 0 :\n",
    "        if len(File['demoFile']) > 0 :\n",
    "            seqFile_train, seqFile_test, labelFile_train, labelFile_test, demoFile_train, demoFile_test = train_test_split(np.array(pickle.load(open(File['seqFile'], 'rb'))), np.array(pickle.load(open(File['labelFile'], 'rb'))), np.array(pickle.load(open(File['demoFile'], 'rb'))), test_size=0.2, random_state=42)\n",
    "            pickle.dump(seqFile_train, open(File['outFile']+'/seqFile_train_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(seqFile_test, open(File['outFile']+'/seqFile_test_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(labelFile_train, open(File['outFile']+'/labelFile_train_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(labelFile_test, open(File['outFile']+'/labelFile_test_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(demoFile_train, open(File['outFile']+'/demoFile_train_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(demoFile_test, open(File['outFile']+'/demoFile_test_gridsearch', 'wb'), -1)\n",
    "        else :\n",
    "            seqFile_train, seqFile_test, labelFile_train, labelFile_test = train_test_split(np.array(pickle.load(open(File['seqFile'], 'rb'))), np.array(pickle.load(open(File['labelFile'], 'rb'))), test_size=0.2, random_state=42)\n",
    "            pickle.dump(seqFile_train, open(File['outFile']+'/seqFile_train_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(seqFile_test, open(File['outFile']+'/seqFile_test_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(labelFile_train, open(File['outFile']+'/labelFile_train_gridsearch', 'wb'), -1)\n",
    "            pickle.dump(labelFile_test, open(File['outFile']+'/labelFile_test_gridsearch', 'wb'), -1)\n",
    "    else :\n",
    "        seqFile_train, seqFile_test = train_test_split(np.array(pickle.load(open(File['seqFile'], 'rb'))), test_size=0.2, random_state=42)\n",
    "        pickle.dump(seqFile_train, open(File['outFile']+'/seqFile_train_gridsearch', 'wb'), -1)\n",
    "        pickle.dump(seqFile_test, open(File['outFile']+'/seqFile_test_gridsearch', 'wb'), -1)\n",
    "            \n",
    "\n",
    "    for embDimSize in embDimSize_list :\n",
    "        for hidden_dim in hiddenDimSize_list :\n",
    "            for window_size in window_size_list :\n",
    "\n",
    "                options_train = {'embDimSize': embDimSize,\n",
    "                        'hiddenDimSize': hidden_dim,\n",
    "                        'windowSize': window_size\n",
    "                        }\n",
    "            \n",
    "                # Training\n",
    "                if len(File['labelFile']) > 0 :\n",
    "                    if len(File['demoFile']) > 0 :\n",
    "                        train_med2vec(seqFile = File['outFile']+'/seqFile_train_gridsearch',\n",
    "                                labelFile = File['outFile']+'/labelFile_train_gridsearch',\n",
    "                                demoFile = File['outFile']+'/demoFile_train_gridsearch',\n",
    "                                outFile = File['outFile'], \n",
    "                                numXcodes = File['numXcodes'],\n",
    "                                numYcodes = File['numYcodes'],\n",
    "                                demoSize = File['demoSize'],\n",
    "                                embDimSize = options_train['embDimSize'], \n",
    "                                hiddenDimSize = options_train['hiddenDimSize'],\n",
    "                                windowSize = options_train['windowSize'],\n",
    "                                batchSize = File['batchSize'],\n",
    "                                maxEpochs = File['maxEpochs'],\n",
    "                                logEps = File['logEps'],\n",
    "                                L2_reg = File['L2_reg'])\n",
    "                    else :\n",
    "                        train_med2vec(seqFile = File['outFile']+'/seqFile_train_gridsearch',\n",
    "                                labelFile = File['outFile']+'/labelFile_train_gridsearch',\n",
    "                                demoFile = '',\n",
    "                                outFile = File['outFile'], \n",
    "                                numXcodes = File['numXcodes'],\n",
    "                                numYcodes = File['numYcodes'],\n",
    "                                demoSize = File['demoSize'],\n",
    "                                embDimSize = options_train['embDimSize'], \n",
    "                                hiddenDimSize = options_train['hiddenDimSize'],\n",
    "                                windowSize = options_train['windowSize'],\n",
    "                                batchSize = File['batchSize'],\n",
    "                                maxEpochs = File['maxEpochs'],\n",
    "                                logEps = File['logEps'],\n",
    "                                L2_reg = File['L2_reg'])\n",
    "                else :\n",
    "                    train_med2vec(seqFile = File['outFile']+'/seqFile_train_gridsearch',\n",
    "                                labelFile = '',\n",
    "                                demoFile = '',\n",
    "                                outFile = File['outFile'], \n",
    "                                numXcodes = File['numXcodes'],\n",
    "                                numYcodes = File['numYcodes'],\n",
    "                                demoSize = File['demoSize'],\n",
    "                                embDimSize = options_train['embDimSize'], \n",
    "                                hiddenDimSize = options_train['hiddenDimSize'],\n",
    "                                windowSize = options_train['windowSize'],\n",
    "                                batchSize = File['batchSize'],\n",
    "                                maxEpochs = File['maxEpochs'],\n",
    "                                logEps = File['logEps'],\n",
    "                                L2_reg = File['L2_reg'])\n",
    "                            \n",
    "            \n",
    "\n",
    "                # Charge the learned model\n",
    "                Filetest = File.copy()\n",
    "                if len(File['labelFile']) > 0 :\n",
    "                    if len(File['demoFile']) > 0 :\n",
    "                        Filetest['seqFile'] = File['outFile']+'/seqFile_test_gridsearch'\n",
    "                        Filetest['labelFile'] = File['outFile']+'/labelFile_test_gridsearch'\n",
    "                        Filetest['demoFile'] = File['outFile']+'/demoFile_test_gridsearch'\n",
    "                    else :\n",
    "                        Filetest['seqFile'] = File['outFile']+'/seqFile_test_gridsearch'\n",
    "                        Filetest['labelFile'] = File['outFile']+'/labelFile_test_gridsearch'\n",
    "                else :\n",
    "                    Filetest['seqFile'] = File['outFile']+'/seqFile_test_gridsearch'\n",
    "                            \n",
    "                loss_value_test = Evaluate_Med2Vec(Filetest, File['outFile']+ '.' +str(File['maxEpochs']-1) + '.npz', options_train)\n",
    "                df_hyperparameters.loc[i, 'embDimSize'], df_hyperparameters.loc[i, 'hiddenDimSize'], df_hyperparameters.loc[i, 'windowSize'], df_hyperparameters.loc[i, 'Loss_test'] = embDimSize, hidden_dim, window_size, round(loss_value_test.item(), 4)\n",
    "                    \n",
    "                i+=1\n",
    "\n",
    "    return df_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Calcul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
