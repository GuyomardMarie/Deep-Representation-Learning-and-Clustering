{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides functions to compute and evaluate Clustering. 2 methods are implemented; K-means and Gaussian Mixture Models (GMM).\n",
    "\n",
    "The different functionalities are the following:\n",
    "\n",
    "- Function to fit clusters: fit_cluster\n",
    "    This function handles 2 types of clustering: K-means and GMM. It necessitates as parameter the number of cluster (resp. guassian mixtures for GMM).\n",
    "\n",
    "- Function to predict clusters: predict_cluster\n",
    "    This function applies the model on a sample to attribute clusters.\n",
    "\n",
    "- Functions to evaluate the clusters on the training sample and validation set: evaluate_cluster_train and evaluate_cluster_validation\n",
    "    These functions compute the following metrics: \n",
    "    - Silhouette score\n",
    "    - Intra-cluster inertia: measures the sum of squares of distances between each data point and its assigned cluster centroid.\n",
    "    - Extra-cluster inertia: measures the total dispersion of data points relative to their centroids.\n",
    "    - Davies-Bouldin index: measures the average similarity between each cluster and its most similar clusters. A lower value indicates better separation between clusters.\n",
    "\n",
    "- Function to optimize the hyperparameter: gridsearch_cluster_hyperparametres\n",
    "    This function aims at selectinig the optimal number of clusters for K-means and Gaussian Mixtures for GMMs.\n",
    "\n",
    "- Function to compute a Cross-Validation: train_cluster_CV\n",
    "    This function:\n",
    "    - Split the sample into a training set (80%) and a test one (20%)\n",
    "    - Train the clustering task on the training set (function fit_cluster)\n",
    "    - The model is then applied to both training and validation sets (function predict_cluster)\n",
    "    - The different metrics are computed on both samples (functions evaluate_cluster_train and evaluate_cluster_validation)\n",
    "    - 2 Dataframes are returned (one on the training and on the validation test) containing for each fold the different metrics\n",
    "\n",
    "- Function to visualize the clusters through PCA or t-SNE dimension reduction techniques: PCA_caracteristic\n",
    "    This function is developed for maximum 5 clusters. It takes as input a dataframe containing the different attributes of the samples (categorical variable, for example Chemiotherapy Y/N or type of Chemiotherapy = {adjuvant, neoadjuvant, both}). For each attribute, a plot is displayed emphasizing the distribution of the different values of attributes regarding the cluster the sample belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cluster(data, method, k):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        Input values.\n",
    "    method : string\n",
    "        Clustering method to apply {'kmeans', 'GMM'}. Default = 'kmeans'.\n",
    "    k : int\n",
    "        For kmeans = number of clusters. For Gaussian Mixture = number of components. Default =2.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : Sklearn model\n",
    "        Fitted model.\n",
    "    '''\n",
    "\n",
    "    if method == 'GMM':\n",
    "        model = GaussianMixture(n_components=k)\n",
    "\n",
    "    else :\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "\n",
    "    model.fit(data)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster(model, data) :\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Sklearn model\n",
    "        Fitted model to apply.\n",
    "    data : array\n",
    "        Input values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    labels : array\n",
    "        The predicted cluster per sample.\n",
    "    '''\n",
    "    \n",
    "    labels = model.predict(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Silhouette score\n",
    "- Intra-cluster inertia: measures the sum of squares of distances between each data point and its assigned cluster centroid.\n",
    "- Extra-cluster inertia: measures the total dispersion of data points relative to their centroids.\n",
    "- Davies-Bouldin index: measures the average similarity between each cluster and its most similar clusters. A lower value indicates better separation between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cluster_train(model, data, label) :\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Sklearn model\n",
    "        Fitted model to apply.\n",
    "    data : array\n",
    "        Training sample.\n",
    "    label : array\n",
    "        The predicted cluster per sample.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dict of evaluations on validation sample : \n",
    "        Kmeans and GMM : silhouette score, inertia intra clusters and extra clusters, Davies-Bouldin index\n",
    "        Agglomeration Clustering : silhouette\n",
    "    '''\n",
    "\n",
    "    silhouette = silhouette_score(data, label)\n",
    "\n",
    "    if str(type(model)) == \"<class 'sklearn.cluster._kmeans.KMeans'>\" :\n",
    "        k = model.n_clusters\n",
    "        cluster_centers_train = model.cluster_centers_\n",
    "    \n",
    "    else :\n",
    "        k = model.n_components\n",
    "        cluster_centers_train = []\n",
    "        for lab in range(k):\n",
    "            cluster_centers_train.append(np.mean(data[label== lab], axis=0))\n",
    "        cluster_centers_train = np.array(cluster_centers_train)\n",
    "\n",
    "    \n",
    "    inertie_intra_cluster = 0\n",
    "    for i in range(k):\n",
    "        cluster_points = data[label == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            cluster_centroid = cluster_centers_train[i]\n",
    "            inertie_intra_cluster += np.sum((cluster_points - cluster_centroid) ** 2)\n",
    "\n",
    "    inertie_extra_cluster = np.sum(np.min(np.linalg.norm(data - cluster_centers_train[label], axis=1) ** 2))\n",
    "\n",
    "    intra_cluster_distances = []\n",
    "    for i in range(k):\n",
    "        if np.sum(label == i) == 0:\n",
    "            intra_cluster_distances.append(0)  \n",
    "        else:\n",
    "            intra_cluster_distances.append(np.mean(pairwise_distances(data[label == i], [cluster_centers_train[i]], metric='euclidean')))\n",
    "    cluster_distances = pairwise_distances(cluster_centers_train, metric='euclidean')\n",
    "    np.fill_diagonal(cluster_distances, np.inf)\n",
    "    db_scores = [(intra_cluster_distances[i] + intra_cluster_distances[j]) / cluster_distances[i, j]\n",
    "                for i in range(k) for j in range(k)]\n",
    "    \n",
    "    db_score_mean, db_score_min, db_score_max = np.mean(db_scores), np.min(db_scores), np.max(db_scores)\n",
    "\n",
    "    return {'silhouette' : round(silhouette,2), 'inertia_intra' : int(inertie_intra_cluster), 'inertia_extra' : round(inertie_extra_cluster,0), 'db_mean' : round(db_score_mean,2), 'db_min':round(db_score_min,2), 'db_max':round(db_score_max,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cluster_validation(model, data_train, data_test, label) :\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Sklearn model\n",
    "        Fitted model to apply.\n",
    "    data : array\n",
    "        Validation sample.\n",
    "    label : array\n",
    "        The predicted cluster per sample.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dict of evaluations on validation sample : silhouette score, inertia intra clusters and extra clusters, Davies-Bouldin index\n",
    "    '''\n",
    "\n",
    "    if str(type(model)) == \"<class 'sklearn.cluster._kmeans.KMeans'>\" :\n",
    "        k = model.n_clusters\n",
    "        cluster_centers_train = model.cluster_centers_\n",
    "        labels_train = model.labels_\n",
    "\n",
    "    else :\n",
    "        k = model.n_components\n",
    "        labels_train = model.predict(data_train)\n",
    "        cluster_centers_train = []\n",
    "        for lab in range(k):\n",
    "            cluster_centers_train.append(np.mean(data_train[labels_train == lab], axis=0))\n",
    "        cluster_centers_train = np.array(cluster_centers_train)\n",
    "\n",
    "    silhouette = silhouette_score(data_test, label)\n",
    "\n",
    "    inertie_intra_cluster = 0\n",
    "    for i in range(k):\n",
    "        cluster_points = data_test[label == i]\n",
    "        if len(cluster_points) > 0:\n",
    "            cluster_centroid = cluster_centers_train[i]\n",
    "            inertie_intra_cluster += np.sum((cluster_points - cluster_centroid) ** 2)\n",
    "\n",
    "    inertie_extra_cluster = np.sum(np.min(np.linalg.norm(data_test - cluster_centers_train[label], axis=1) ** 2))\n",
    "\n",
    "    intra_cluster_distances = []\n",
    "    for i in range(k):\n",
    "        if np.sum(label == i) == 0:\n",
    "            intra_cluster_distances.append(0) \n",
    "        else:\n",
    "            intra_cluster_distances.append(np.mean(pairwise_distances(data_test[label == i], [cluster_centers_train[i]], metric='euclidean')))\n",
    "    cluster_distances = pairwise_distances(cluster_centers_train, metric='euclidean')\n",
    "    np.fill_diagonal(cluster_distances, np.inf)\n",
    "    db_scores = [(intra_cluster_distances[i] + intra_cluster_distances[j]) / cluster_distances[i, j]\n",
    "                for i in range(k) for j in range(k)]\n",
    "    \n",
    "    db_score_mean, db_score_min, db_score_max = np.mean(db_scores), np.min(db_scores), np.max(db_scores)\n",
    "\n",
    "    return {'silhouette' : silhouette, 'inertia_intra' : int(inertie_intra_cluster), 'inertia_extra' : round(inertie_extra_cluster,0), 'db_mean' : round(db_score_mean,2), 'db_min':round(db_score_min,2), 'db_max':round(db_score_max,2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "\n",
    "Selection of the optimal number of clusters for K-means and Gaussian Mixtures for GMMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_cluster_hyperparametres(method, data, max_clusters=10, nb_folds = 5):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : string\n",
    "        Clustering method to apply {'kmeans', 'GMM'}. Default = 'kmeans'.\n",
    "    data : array\n",
    "        Input values.\n",
    "    max_clusters : int\n",
    "        Maximum number of clusters to test. Default = 10.\n",
    "    nb_folds : int \n",
    "        Number of folds for the Cross Validation. Default = 5.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        For each number of clusters tested, the averaged silhouette scores (both on training and test samples) over the nb_folds cross validation.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    j=0\n",
    "   \n",
    "    for k in range(2, max_clusters+1):\n",
    "        silhouette_train_list, silhouette_test_list = [],[]\n",
    "        for i in range(nb_folds) :\n",
    "            X_train, X_test = train_test_split(data, test_size=0.2)\n",
    "            model = fit_cluster(X_train, method, k)\n",
    "            labels_train = predict_cluster(model, X_train)\n",
    "            labels_test = predict_cluster(model, X_test)\n",
    "            silhouette_train_list.append(silhouette_score(X_train, labels_train))\n",
    "            silhouette_test_list.append(silhouette_score(X_test, labels_test))\n",
    "\n",
    "        df.loc[j, 'k'], df.loc[j, 'Silhouette_train'], df.loc[j, 'Silhouette_test'] = k, round(np.mean(silhouette_train_list),4), round(np.mean(silhouette_test_list),4)\n",
    "        j+=1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cluster_CV(method, data, k, nb_folds = 5):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : string\n",
    "        Clustering method to apply {'kmeans', 'GMM'}. Default = 'kmeans'.\n",
    "    data : array\n",
    "        Input values.\n",
    "    k : int\n",
    "        Numver of clusters.\n",
    "    nb_folds : int \n",
    "        Number of folds for the Cross Validation. Default = 5.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        For each clusters fitted (number of folds), the averaged metrics (both on training and test samples) over the nb_folds cross validation.\n",
    "    '''\n",
    "    \n",
    "    df_train, df_test = pd.DataFrame(columns=['Silhouette', 'Inertia_intra', 'Inertia_extra', 'DB_mean', 'DB_min', 'DB_max']), pd.DataFrame(columns=['Silhouette', 'Inertia_intra', 'Inertia_extra', 'DB_mean', 'DB_min', 'DB_max'])\n",
    "\n",
    "    for i in range(nb_folds) :\n",
    "        X_train, X_test = train_test_split(data, test_size=0.3)\n",
    "        model = fit_cluster(X_train, method, k)\n",
    "        labels_train = predict_cluster(model, X_train)\n",
    "        labels_test = predict_cluster(model, X_test)\n",
    "        eval_train = evaluate_cluster_train(model, X_train, labels_train)\n",
    "        eval_test = evaluate_cluster_validation(model, X_train, X_test, labels_test)\n",
    "        df_train.loc[i, 'Silhouette'], df_train.loc[i, 'Inertia_intra'], df_train.loc[i, 'Inertia_extra'], df_train.loc[i, 'DB_mean'], df_train.loc[i, 'DB_min'], df_train.loc[i, 'DB_max'] = eval_train['silhouette'], eval_train['inertia_intra'], eval_train['inertia_extra'], eval_train['db_mean'], eval_train['db_min'], eval_train['db_max']\n",
    "        df_test.loc[i, 'Silhouette'], df_test.loc[i, 'Inertia_intra'], df_test.loc[i, 'Inertia_extra'], df_test.loc[i, 'DB_mean'], df_test.loc[i, 'DB_min'], df_test.loc[i, 'DB_max'] = eval_test['silhouette'], eval_test['inertia_intra'], eval_test['inertia_extra'], eval_test['db_mean'], eval_test['db_min'], eval_test['db_max']\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_caracteristic(data, columns_list, k=2, path='', loc_legend2 = 'best'):\n",
    "    '''\n",
    "    This function is only suitable for 2 clusters and 2 dimensional PCA or T-SNE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        DataFrame containing the clusters 'Cluster', the two pricipal components resulting form a PCA or a T-SNE in two dimensions 'PC1', 'PC2' and the caracteristics of the population, on which we apply the visualization.\n",
    "    colums_list : list\n",
    "        List containing the name of the columns (ie. variables) on which we want to realize the plot.\n",
    "    k : int\n",
    "        Number of clusters.\n",
    "    path : str\n",
    "        Path and name of the resulting figure(s).\n",
    "    loc_legend2 : str\n",
    "        Localization for the legend of the different unique values for the characteristics of the population (a variable, ie. a column). \n",
    "    '''\n",
    "\n",
    "    liste_markers = ['o', 's', '^', 'd', 'X']\n",
    "\n",
    "    for col in columns_list : \n",
    "\n",
    "        fig, axs = plt.subplots(ncols=3, nrows=math.ceil((len(np.unique(data[col]))+1)/3),figsize=(15, 4*math.ceil((len(np.unique(data[col]))+1)/3)))\n",
    "\n",
    "        if (len(np.unique(data[col]))+1)%3 != 0 :\n",
    "            if math.floor((len(np.unique(data[col]))+1)/3)==1:\n",
    "                fig.delaxes(axs[math.ceil((len(np.unique(data[col]))+1)/3)-1, -1])\n",
    "            else :\n",
    "                for l in range(1,math.floor((len(np.unique(data[col]))+1)/3)):\n",
    "                    fig.delaxes(axs[math.ceil((len(np.unique(data[col]))+1)/3)-1, -l])\n",
    "\n",
    "        if len(np.unique(data[col])) == 2 :\n",
    "            colors = ['mediumblue', 'darkorange']\n",
    "        elif len(np.unique(data[col])) == 3 :\n",
    "            colors = ['mediumblue', 'limegreen', 'gold']\n",
    "        elif len(np.unique(data[col])) > 5 :\n",
    "            colors = ['mediumblue', 'teal', 'limegreen', 'gold', 'darkorange', 'deeppink', 'darkviolet', 'chocolate']\n",
    "        else :\n",
    "            colors = ['mediumblue', 'teal', 'limegreen', 'gold', 'darkorange']\n",
    "        \n",
    "\n",
    "        for i, ax in enumerate(axs.ravel()):\n",
    "            if i <= len(np.unique(data[col])) :\n",
    "                if i == 0:\n",
    "                    for cluster in range(k):\n",
    "                        if cluster == 0 :\n",
    "                            # Cluster 1\n",
    "                            j = 0\n",
    "                            cluster_data = data[data['Cluster'] == cluster]\n",
    "                            for var in data[col].unique():\n",
    "                                var_data = cluster_data[cluster_data[col] == var]\n",
    "                                ax.scatter(var_data['PC1'], var_data['PC2'], label=f'{var}', c=colors[j], marker=liste_markers[cluster], alpha=0.6)\n",
    "                                j += 1\n",
    "\n",
    "                        else :\n",
    "                            # Clusters 2 à k\n",
    "                            j = 0\n",
    "                            cluster_data = data[data['Cluster'] == cluster]\n",
    "                            for var in data[col].unique():\n",
    "                                var_data = cluster_data[cluster_data[col] == var]\n",
    "                                ax.scatter(var_data['PC1'], var_data['PC2'], c=colors[j], marker=liste_markers[cluster], alpha=0.6)\n",
    "                                j += 1\n",
    "\n",
    "                    ax2 = ax.twinx()\n",
    "                    ax2.get_yaxis().set_visible(False)\n",
    "                    for cluster in range(k) :\n",
    "                        ax2.plot(np.NaN, np.NaN, linestyle=\"none\", marker=liste_markers[cluster], markersize=7, markerfacecolor=\"black\", label='Cluster ' + str(cluster+1))\n",
    "\n",
    "                    # Création de la légende pour les BC Sub Type\n",
    "                    list_caracteristic = []\n",
    "                    for cc, var in enumerate(data[col].unique()):\n",
    "                        list_caracteristic.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[cc], markersize=7, label=var, alpha=0.6))\n",
    "\n",
    "                    # Affichage des légendes\n",
    "                    ax.set_xlabel('PC1')\n",
    "                    ax.set_ylabel('PC2')\n",
    "                    #ax.set_title(col)\n",
    "                    if loc_legend2 != 'best':\n",
    "                        ax.legend(handles=list_caracteristic, title=col, fontsize=7, title_fontsize=8, loc=loc_legend2)\n",
    "                    else :\n",
    "                        ax.legend(handles=list_caracteristic, title=col, fontsize=7, title_fontsize=8)\n",
    "                    ax2.legend(loc='upper left', title='Clusters', fontsize=7, title_fontsize=8)\n",
    "\n",
    "                    ax.grid(False)\n",
    "                    \n",
    "                    plt.savefig(path+'_'+col+'.PNG')\n",
    "\n",
    "                else :\n",
    "                    for cluster in range(k):\n",
    "                        if cluster == 0 :\n",
    "                            # Cluster 1\n",
    "                            list_caracteristic = []\n",
    "                            cluster_data = data[data['Cluster'] == cluster]\n",
    "                            for var in data[col].unique():\n",
    "                                var_data = cluster_data[cluster_data[col] == var]\n",
    "                                if var == data[col].unique()[i-1] :\n",
    "                                    ax.scatter(var_data['PC1'], var_data['PC2'], label=f'{var}', c='mediumblue', marker=liste_markers[cluster], alpha=0.8)\n",
    "                                    list_caracteristic.append(plt.Line2D([0], [0], marker=liste_markers[cluster], color='w', markerfacecolor='mediumblue', markersize=7, label=var, alpha=0.8))\n",
    "                                else :\n",
    "                                    ax.scatter(var_data['PC1'], var_data['PC2'], label=f'{var}', c='gray', marker=liste_markers[cluster], alpha=0.4)\n",
    "                                    list_caracteristic.append(plt.Line2D([0], [0], marker=liste_markers[cluster], color='w', markerfacecolor='gray', markersize=7, label=var, alpha=0.4))\n",
    "\n",
    "                        else :\n",
    "                            # Clusters 2 à k\n",
    "                            cluster_data = data[data['Cluster'] == cluster]\n",
    "                            for var in data[col].unique():\n",
    "                                var_data = cluster_data[cluster_data[col] == var]\n",
    "                                if var == data[col].unique()[i-1] :\n",
    "                                    ax.scatter(var_data['PC1'], var_data['PC2'], label=f'{var}', c='mediumblue', marker=liste_markers[cluster], alpha=0.8)\n",
    "                                else :\n",
    "                                    ax.scatter(var_data['PC1'], var_data['PC2'], label=f'{var}', c='gray', marker=liste_markers[cluster], alpha=0.4)\n",
    "\n",
    "                        ax2 = ax.twinx()\n",
    "                        ax2.get_yaxis().set_visible(False)\n",
    "                        for cluster in range(k) :\n",
    "                            ax2.plot(np.NaN, np.NaN, linestyle=\"none\", marker=liste_markers[cluster], markersize=7, markerfacecolor=\"black\", label='Cluster ' + str(cluster+1))\n",
    "\n",
    "                    ax.set_xlabel('PC1')\n",
    "                    ax.set_ylabel('PC2')\n",
    "                    #ax.set_title(col)\n",
    "                    if loc_legend2 != 'best':\n",
    "                        ax.legend(handles=list_caracteristic, title=col, fontsize=7, title_fontsize=8, loc=loc_legend2)\n",
    "                    else :\n",
    "                        ax.legend(handles=list_caracteristic, title=col, fontsize=7, title_fontsize=8)\n",
    "                    ax2.legend(loc='upper left', title='Clusters', fontsize=7, title_fontsize=8)\n",
    "\n",
    "                    ax.grid(False)\n",
    "\n",
    "                    plt.savefig(path+'_'+col+'.PNG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
